{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8baf3e70-686d-4164-87d3-5f0d5f80486c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      4\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mTOKENIZERS_PARALLELISM\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "from transformers import TrainerCallback\n",
    "from ray import train, tune\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "from ray.train.huggingface.transformers import prepare_trainer\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "\n",
    "from gliner import GLiNER\n",
    "from gliner.training import Trainer, TrainingArguments\n",
    "from gliner.data_processing.collator import DataCollatorWithPadding\n",
    "from gliner.data_processing import GLiNERDataset\n",
    "\n",
    "from utils import formatting_prompts_func, convert_to_gliner_dataset, combine_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541de136c8bc3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"jjzha/skillspan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4648bc-456c-41f1-b454-1ce4e723ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"jjzha/skillspan\")\n",
    "ds = ds.map(formatting_prompts_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146be80-4267-4aa4-bc92-39f1f7ee0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_to_gliner_dataset(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2869b-08ef-4a4c-b3ff-5d0dc306aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510a2a4-5ffc-44b3-a3b4-95a9dde91c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['validation'] = ds['validation'].map(function=combine_entities, batched=False)\n",
    "ds['test'] = ds['test'].map(function=combine_entities, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927bbda-74d0-4cb5-9217-b98ae5e58fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(TrainerCallback):\n",
    "\n",
    "    def on_log(self, args, state, control, model, tokenizer, **kwargs):\n",
    "        labels = [\"Skill\", \"Knowledge\"]\n",
    "        pred_gli = []\n",
    "\n",
    "        sentences = ds['validation']['sentence'][:]\n",
    "        batch_size = 64\n",
    "        # Generate batches\n",
    "        for i in range(0, len(sentences), batch_size):\n",
    "            # Yield successive batches of size batch_size\n",
    "            text = sentences[i:i + batch_size]\n",
    "            entities = model.batch_predict_entities(text, labels, threshold=0.82)\n",
    "            pred_gli.extend(entities)\n",
    "        \n",
    "        evaluator = Evaluator(ds['validation']['knowledge_and_skill'][:], pred_gli, tags=['Skill', 'Knowledge'])\n",
    "        # Returns overall metrics and metrics for each tag\n",
    "        results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "        f1 = {\"f1\": results['strict']['f1']}\n",
    "        train.report(metrics=f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab35c3-a8e7-401b-931e-f3c8e2cd8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gliner(config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Data Setup\n",
    "    model = GLiNER.from_pretrained(\"EmergentMethods/gliner_small_news-v2.1\",model_max_length=512)\n",
    "    train_dataset = GLiNERDataset(train_data, model.config, data_processor=model.data_processor)\n",
    "    data_collator = DataCollatorWithPadding(model.config)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    max_steps = config['max_steps']\n",
    "    logging_steps = 10\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=train.get_context().get_trial_dir(),\n",
    "        do_eval = False,\n",
    "        learning_rate=config['lr'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        others_lr= config['others_lr'],\n",
    "        others_weight_decay=0.01,\n",
    "        lr_scheduler_type=config['scheduler'], #cosine\n",
    "        optim = config['optim'],\n",
    "        warmup_ratio=0.1,\n",
    "        max_grad_norm = config['max_grad_norm'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=8,\n",
    "        max_steps = max_steps,\n",
    "        logging_steps = logging_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps = logging_steps*2,\n",
    "        save_total_limit = 2,\n",
    "        dataloader_num_workers = 8,\n",
    "        use_cpu = False,\n",
    "        report_to=\"none\",\n",
    "        )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        tokenizer=model.data_processor.transformer_tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[MyCallback()]\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38945604-bd40-49fe-9971-aab4ed96e396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%m_%d_%H_%M\")\n",
    "\n",
    "trainable_with_resources = tune.with_resources(train_gliner,{\"cpu\":7,\"gpu\": 1})\n",
    "max_concurrent_trials = torch.cuda.device_count()\n",
    "\n",
    "## with search algorithm\n",
    "algo = OptunaSearch()\n",
    "\n",
    "# Hyperparameter search space\n",
    "search_space = {\n",
    "    \"lr\": tune.quniform(10e-5, 30e-5, 2e-5),\n",
    "    \"others_lr\": tune.quniform(3e-5, 10e-5, 1e-5),\n",
    "    \"max_steps\": tune.choice([400]),\n",
    "    \"weight_decay\": tune.quniform(0.03, 0.07, 0.01),\n",
    "    \"scheduler\": tune.choice([\"linear\"]), \n",
    "    'batch_size': tune.choice([32]),\n",
    "    \"max_grad_norm\": tune.quniform(0.3, 0.8, 0.1),\n",
    "    \"optim\": tune.choice(['adamw_torch_fused'])\n",
    "}\n",
    "wb_project = f\"raytune_gliner_{formatted_datetime}\"\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    param_space=search_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=10,\n",
    "        search_alg=algo,\n",
    "        metric=\"f1\",\n",
    "        mode=\"max\",\n",
    "        max_concurrent_trials=max_concurrent_trials,\n",
    "        scheduler=ASHAScheduler(grace_period=30)\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        callbacks=[WandbLoggerCallback(project=wb_project)],\n",
    "        storage_path=\"~/raytune/checkpoint\"\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e72a00-f7a6-4dde-af8a-07d926485990",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {result.path: result.metrics_dataframe for result in results}\n",
    "# Plot by epoch\n",
    "ax = None  # This plots everything on the same plot\n",
    "for d in dfs.values():\n",
    "    ax = d.f1.plot(ax=ax, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bdb098-6a46-4150-a298-3887b922da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(\"f1\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1eb28a-93e0-4d14-ae4b-e045f9c96d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450a422-3401-4a5a-ac5f-3f0406358bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269c572-ef4b-47cb-b394-5007f480e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Raytune doesn't keep track of the best iteration (checkpoint) with the current version and with the current evaluation setup, make sure to select the best model path and checkpoint based on the F1 chart from your reporting tool (e.g. WandB or Tensorboard)\n",
    "md = GLiNER.from_pretrained(f'{best_result.path}/checkpoint-400', load_tokenizer=True, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3690c8-e71d-46de-80c7-7bf3d71e4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ds['validation']['sentence'][:]\n",
    "labels = ['Skill', 'Knowledge']\n",
    "y = ds['validation']['knowledge_and_skill'][:]\n",
    "\n",
    "pred_gli = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "md.to(device)\n",
    "batch_size = 64\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    # Yield successive batches of size batch_size\n",
    "    text = sentences[i:i + batch_size]\n",
    "    entities = md.batch_predict_entities(text, labels, threshold=0.89)\n",
    "    pred_gli.extend(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74a609-32d4-45f2-9ca0-307196eb7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_threshold(threshold):\n",
    "    pred_gli_threshold = []\n",
    "    for i in pred_gli:\n",
    "        if len(i) ==0:\n",
    "            pred_gli_threshold.append(i)\n",
    "        else:\n",
    "            pred_gli_threshold.append([j for j in i if j['score']> threshold])\n",
    "            \n",
    "    evaluator = Evaluator(y, pred_gli_threshold, tags=['Skill', 'Knowledge'])\n",
    "    results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "    f1 = results['strict']['f1']\n",
    "    return {\"threshold\": threshold, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84aad5b-7ef0-4d31-a2b5-f67fb306420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "res = Parallel(n_jobs=-1)(delayed(proc_threshold)(i / 100) for i in range(5, 100, 1))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd13ac3de40f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the threshold For GLiNER based on the best performance on the dev set\n",
    "threshold = pd.DataFrame(res).sort_values(by='f1', ascending=False).iloc[0]['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85203f5d-bd9f-4409-bdf3-9c45d6ac1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ds['validation']['sentence'][:]\n",
    "labels = ['Skill', 'Knowledge']\n",
    "y = ds['validation']['knowledge_and_skill'][:]\n",
    "\n",
    "pred_gli = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "md.to(device)\n",
    "batch_size = 64\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    # Yield successive batches of size batch_size\n",
    "    text = sentences[i:i + batch_size]\n",
    "    entities = md.batch_predict_entities(text, labels, threshold=threshold)\n",
    "    pred_gli.extend(entities)\n",
    "evaluator = Evaluator(y, pred_gli, tags=['Skill', 'Knowledge'])\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "results['strict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603a0d5-8cc7-43fb-b0ce-df9a76141add",
   "metadata": {},
   "outputs": [],
   "source": [
    "{entity: entity_metric['strict'] for entity, entity_metric in results_per_tag.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91833b46a6bf1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ds['test']['sentence'][:]\n",
    "labels = ['Skill', 'Knowledge']\n",
    "y = ds['test']['knowledge_and_skill'][:]\n",
    "\n",
    "pred_gli = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "md.to(device)\n",
    "batch_size = 64\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    # Yield successive batches of size batch_size\n",
    "    text = sentences[i:i + batch_size]\n",
    "    entities = md.batch_predict_entities(text, labels, threshold=threshold)\n",
    "    pred_gli.extend(entities)\n",
    "evaluator = Evaluator(y, pred_gli, tags=['Skill', 'Knowledge'])\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "results['strict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdd3dc-6ec3-4a73-ad1c-e4d37aef05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "{entity: entity_metric['strict'] for entity, entity_metric in results_per_tag.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b1869-6006-4236-aa9e-36678c43b9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
